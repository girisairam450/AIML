{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division, print_function, unicode_literals\n",
    " \n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    " \n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--LsaSummarizer--\n",
      "Hi Jane,\n",
      "Thank you for keeping me updated on this issue.\n",
      "I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again.\n",
      "Also many thanks for your suggestions.\n",
      "We hope to improve this feature in the future.\n",
      "In case you experience any further problems with the app, please don't hesitate to contact me again.\n",
      "Best regards,\n",
      "John Doe Customer Support\n",
      "1600 Amphitheatre Parkway Mountain View, CA United States\n",
      "--LuhnSummarizer--\n",
      "Hi Jane,\n",
      "Thank you for keeping me updated on this issue.\n",
      "I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again.\n",
      "Also many thanks for your suggestions.\n",
      "We hope to improve this feature in the future.\n",
      "In case you experience any further problems with the app, please don't hesitate to contact me again.\n",
      "Best regards,\n",
      "John Doe Customer Support\n",
      "1600 Amphitheatre Parkway Mountain View, CA United States\n",
      "--EdmundsonSummarizer--\n",
      "Hi Jane,\n",
      "Thank you for keeping me updated on this issue.\n",
      "I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again.\n",
      "Also many thanks for your suggestions.\n",
      "We hope to improve this feature in the future.\n",
      "In case you experience any further problems with the app, please don't hesitate to contact me again.\n",
      "Best regards,\n",
      "John Doe Customer Support\n",
      "1600 Amphitheatre Parkway Mountain View, CA United States\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE = \"english\"\n",
    "SENTENCES_COUNT = 10\n",
    " \n",
    " \n",
    "    \n",
    "#url=\"https://en.wikipedia.org/wiki/Deep_learning\"\n",
    "#parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))\n",
    "\n",
    "# or for plain text files\n",
    "parser = PlaintextParser.from_file(\"../src/Email.txt\", Tokenizer(LANGUAGE))\n",
    "\n",
    "\n",
    "\n",
    "print (\"--LsaSummarizer--\")    \n",
    "summarizer = LsaSummarizer()\n",
    "summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence)\n",
    "\n",
    "print (\"--LuhnSummarizer--\")     \n",
    "summarizer = LuhnSummarizer() \n",
    "summarizer = LsaSummarizer(Stemmer(LANGUAGE))\n",
    "summarizer.stop_words = (\"I\", \"am\", \"the\", \"you\", \"are\", \"me\", \"is\", \"than\", \"that\", \"this\",)\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence)\n",
    "\n",
    "print (\"--EdmundsonSummarizer--\")     \n",
    "summarizer = EdmundsonSummarizer() \n",
    "words = (\"deep\", \"learning\", \"neural\" )\n",
    "summarizer.bonus_words = words\n",
    "\n",
    "words = (\"another\", \"and\", \"some\", \"next\",)\n",
    "summarizer.stigma_words = words\n",
    "\n",
    "\n",
    "words = (\"another\", \"and\", \"some\", \"next\",)\n",
    "summarizer.null_words = words\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skipthoughts'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-36f7d4d5fa8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mskipthoughts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skipthoughts'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import skipthoughts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You would need to download pre-trained models first\n",
    "model = skipthoughts.load_model()\n",
    "\n",
    "encoder = skipthoughts.Encoder(model)\n",
    "encoded = encoder.encode(sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
